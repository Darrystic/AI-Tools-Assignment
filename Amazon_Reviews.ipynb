{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1AZdD720rwyluX5lN61OeG4RmSY4ksTAL",
      "authorship_tag": "ABX9TyOiX6+kXXtdfrMhNJs3FNai",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Darrystic/AI-Tools-Assignment/blob/main/Amazon_Reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# notebooks/03_spacy_ner_reviews.ipynb\n"
      ],
      "metadata": {
        "id": "uMiLb6J75hSx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlkk0SVrxhbH",
        "outputId": "3b3ff593-f033-4975-c90f-e732e87fb012"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decompressing Amazon Reviews dataset...\n",
            "Partial extraction complete (20,000 lines).\n",
            "  label                                             review\n",
            "0     2  Stuning even for the non-gamer: This sound tra...\n",
            "1     2  The best soundtrack ever to anything.: I'm rea...\n",
            "2     2  Amazing!: This soundtrack is my favorite music...\n",
            "3     2  Excellent Soundtrack: I truly like this soundt...\n",
            "4     2  Remember, Pull Your Jaw Off The Floor After He...\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\n",
            "Review: Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recome...\n",
            "Detected brands: []\n",
            "spaCy entities: [('Chrono Cross', 'ORG')]\n",
            "Rule sentiment: neutral\n",
            "\n",
            "Review: The best soundtrack ever to anything.: I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I...\n",
            "Detected brands: []\n",
            "spaCy entities: [(\"Yasunori Mitsuda's\", 'PERSON'), ('years', 'DATE'), ('every penny', 'MONEY')]\n",
            "Rule sentiment: positive\n",
            "\n",
            "Review: Amazing!: This soundtrack is my favorite music of all time, hands down. The intense sadness of \"Prisoners of Fate\" (whic...\n",
            "Detected brands: []\n",
            "spaCy entities: [('Prisoners of Fate', 'WORK_OF_ART'), ('A Distant Promise', 'WORK_OF_ART'), ('Chrono Cross', 'WORK_OF_ART'), ('Time', 'ORG'), ('Scar~', 'ORG'), ('Chronomantique', 'PERSON'), ('Chrono Trigger', 'PERSON'), ('Xenogears', 'DATE'), ('6', 'CARDINAL')]\n",
            "Rule sentiment: positive\n"
          ]
        }
      ],
      "source": [
        "# === Kaggle API Setup ===\n",
        "!pip install -q kaggle\n",
        "\n",
        "import os\n",
        "import bz2\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "\n",
        "# === Step 1: Locate and extract the correct dataset file ===\n",
        "compressed_file = \"data/train.ft.txt.bz2\"\n",
        "extracted_file = \"data/train.ft.txt\"\n",
        "\n",
        "# If the dataset was unzipped but still compressed in .bz2, decompress it\n",
        "if os.path.exists(compressed_file) and not os.path.exists(extracted_file):\n",
        "    print(\"Decompressing Amazon Reviews dataset...\")\n",
        "    with bz2.open(compressed_file, \"rt\", encoding=\"utf-8\") as bzfile, open(extracted_file, \"w\", encoding=\"utf-8\") as outfile:\n",
        "        for i, line in enumerate(bzfile):\n",
        "            outfile.write(line)\n",
        "            if i > 20000:  # decompress only first 20k lines to save time and memory\n",
        "                break\n",
        "    print(\"Partial extraction complete (20,000 lines).\")\n",
        "\n",
        "# Check the extracted file exists\n",
        "if not os.path.exists(extracted_file):\n",
        "    raise FileNotFoundError(\"train.ft.txt still not found. Check if the Kaggle dataset unzipped properly.\")\n",
        "\n",
        "# === Step 2: Load a manageable sample ===\n",
        "sample_lines = []\n",
        "with open(extracted_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i >= 500:\n",
        "            break\n",
        "        label, text = line.split(\" \", 1)\n",
        "        sample_lines.append({\"label\": label.replace(\"__label__\", \"\"), \"review\": text.strip()})\n",
        "\n",
        "df = pd.DataFrame(sample_lines)\n",
        "print(df.head())\n",
        "\n",
        "# === Step 3: NLP Analysis with spaCy ===\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
        "\n",
        "brands = [\"Amazon\", \"Sony\", \"Apple\", \"Samsung\", \"HP\", \"Lenovo\"]\n",
        "matcher.add(\"BRAND\", [nlp.make_doc(b) for b in brands])\n",
        "\n",
        "pos_words = {\"great\", \"excellent\", \"love\", \"good\", \"perfect\", \"amazing\"}\n",
        "neg_words = {\"bad\", \"terrible\", \"poor\", \"hate\", \"disappointing\"}\n",
        "\n",
        "for i in range(3):\n",
        "    text = df.loc[i, \"review\"]\n",
        "    doc = nlp(text)\n",
        "    matches = matcher(doc)\n",
        "    found_brands = [doc[start:end].text for _, start, end in matches]\n",
        "    tokens = {t.lemma_.lower() for t in doc}\n",
        "    score = sum(1 for w in tokens if w in pos_words) - sum(1 for w in tokens if w in neg_words)\n",
        "    sentiment = \"positive\" if score > 0 else \"negative\" if score < 0 else \"neutral\"\n",
        "\n",
        "    print(f\"\\nReview: {text[:120]}...\")\n",
        "    print(f\"Detected brands: {found_brands}\")\n",
        "    print(f\"spaCy entities: {[ (ent.text, ent.label_) for ent in doc.ents ]}\")\n",
        "    print(f\"Rule sentiment: {sentiment}\")\n"
      ]
    }
  ]
}